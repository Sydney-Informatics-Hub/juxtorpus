{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12a0db354ad54515",
   "metadata": {},
   "source": [
    "# ANZCA 2023 - Digital Methods Workshop\n",
    "## Juxtorpus: Understanding your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613559fc8373714c",
   "metadata": {},
   "source": [
    "### Definitions\n",
    "**Corpus**\n",
    "\n",
    "A corpus is a (usually large) collection of documents of a similar kind. An example of a corpus would be essays from a particular author.\n",
    "Documents in a corpus are typically assumed to be in the same format as each other and to share a theme or subject-matter.\n",
    "\n",
    "**Metadata**\n",
    "\n",
    "Metadata is data that describes the dataset in question. Examples of metadata of a news article would be the author or date published. Metadata provides context for data so that we can perform more informed analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1652c485be4f9a",
   "metadata": {},
   "source": [
    "### Example data set: Internet news data with readers engagement\n",
    "Access link: https://www.kaggle.com/datasets/szymonjanowski/internet-articles-data-with-users-engagement\n",
    "\n",
    "Context:\n",
    "\n",
    "This dataset was created and used in order to determine the popularity of an article before it was published online but thanks to its flexibility can be used in various tasks.\n",
    "It contains articles (listed as the top in popularity at the publisher website) from multiple well-known publishers. Then using Facebook GraphAPI data was enriched with engagement features such as shares, reactions, and comments count.\n",
    "\n",
    "Date range: 03-09-2019 to 04-11-2019"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45df14eff573ad7",
   "metadata": {},
   "source": [
    "### Data Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8265944ebd480e31",
   "metadata": {},
   "source": [
    "Data always comes with context and bias. It is part of our job when analysing data to understand the data's context and account for it when drawing conclusions. One method of accounting for the context of data is data cleaning. The following changes to the example data set have been made to more easily achieve our analysis goals:\n",
    "\n",
    "- only the relevant columns were preserved. Columns such as 'url' have been removed. This speeds up processing times and makes loading easier\n",
    "- the article contents column has been edited to improve term frequency analysis:\n",
    "    - most entries in the 'content' column ended with a statement like \"â€¦ \\[+100 chars\\]\". We can infer that this is not from the articles themselves, but is an artifact of the parsing tool used to gather the articles (most likely to keep the file size small). Performing frequency analysis prior to this amendment yielded \"chars\" as by far the most frequently used term\n",
    "- often data analysis tools contain rudamentary data cleaning functionality. In the timeline tool demonstrated in this notebook, there is a checkbox titled \"Remove stopwords\", which allows the ignoring of terms such as \"but\", \"and\", and \"the\". Be mindful of the data cleaning functionalities available to you so that you don't make unnecessary changes to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f586968c4a3ef4c",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd47c715648ec647",
   "metadata": {},
   "source": [
    "#### Corpus Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32c2859a0c36128",
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from juxtorpus.corpus.corpora import Corpora\n",
    "from juxtorpus import Jux\n",
    "from juxtorpus.viz.item_timeline import ItemTimeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "corpora = Corpora()\n",
    "corpora.widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46771c5bfd6b61e7",
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus_ls = [corpora.get(c) for c in corpora.items()]\n",
    "corpus_ls[-1].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e17a3b0ab2b02",
   "metadata": {},
   "source": [
    "#### Author publishing frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfda90d9ab93398",
   "metadata": {},
   "source": [
    "Below we can start to see some patterns and limitations within our example data:\n",
    "- individual author names are conflated with publication names. We can mitigate this by deselecting the publication names in the visualisation\n",
    "- some publications have duplicate entries (BBC News and https://www.facebook.com/bbcnews)\n",
    "- some dates are conspicuously missing any entries at all (Sept 21st to Sept 25th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2d553bc43b14f6",
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus_ls = [corpora.get(c) for c in corpora.items()]\n",
    "corpus = corpus_ls[-1]\n",
    "corpus.create_custom_dtm(lambda x: [x])\n",
    "timeline = ItemTimeline.from_corpus(corpus, freq='1d', use_custom_dtm=True)\n",
    "timeline.widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18c45da5bd22274",
   "metadata": {},
   "source": [
    "#### Term frequency over time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f063e2b014488ce",
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus_ls = [corpora.get(c) for c in corpora.items()]\n",
    "corpus = corpus_ls[-1]\n",
    "timeline = ItemTimeline.from_corpus(corpus, freq='1d')\n",
    "timeline.widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59e8984-54ac-45e3-bed3-bf781b7843f3",
   "metadata": {},
   "source": [
    "#### Term frequency by news source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64f02b3-9196-45b5-9dd1-33ae894f58f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus_ls = [corpora.get(c) for c in corpora.items()]\n",
    "corpus_a = corpus_ls[-1]\n",
    "corpus_b = corpus_ls[-2]\n",
    "jux = Jux(corpus_a, corpus_b)\n",
    "jux.polarity.wordcloud('tf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
