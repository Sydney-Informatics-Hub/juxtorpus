{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b317acfb-9ab6-4a9a-8517-98798b447f07",
   "metadata": {},
   "source": [
    "## A Taster to the Juxtorpus\n",
    "\n",
    "This notebook showcases some usages of the ATAP Juxtorpus tool, which includes two major components: **Corpus** and **Jux**. \n",
    "The **Corpus** package enables the user to upload, select and build their texts as a Corpus object. The Corpus can then be explored and sliced flexibly into sub-corpus based on various metadata or text patterns within the contents. Several out-of-box tools and visualisations come with the Corpus object so that the user can quickly explore the Corpus and sub-Corpus in a unified manner, and more functions will be developed for similar purposes.\n",
    "\n",
    "The **Jux** package, on the other hand, is a simpler tool designed to compare and identify the contrasts between a pair of corpora. Although the comparison sounds like a simple task, when this is conducted on corpora refined with specific conditions and using different metrics of comparison, a lot of insights could be extracted from the analysis.\n",
    "\n",
    "Besides the two new packages to the ATAP text analytic tool suite, this notebook will also demostrate how to integrate other ATAP tools together with the corpus in order to create a reuseable workflow for your research, these include _Concordance Tool_, _Quotations Tool_, _Semantic Tagger_, _Text Similarity Scorer_ etc.\n",
    "\n",
    "Interactive Widgets were developed for several common functions to make the operations easier for people without technical backgrounds, and this notebook demonstrate both method if a widget is available for the operation.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>User guide to using a Jupyter Notebook</b> \n",
    "\n",
    "If you are new to Jupyter Notebook, feel free to take a quick look at [this user guide](https://github.com/Australian-Text-Analytics-Platform/semantic-tagger/blob/main/documents/jupyter-notebook-guide.pdf) for basic information on how to use a notebook.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8264119f-9240-46e1-ae75-8af488f2a52c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> .jp-Button path { fill: #616161;} text.terms { fill: #616161;} .jp-icon-warn0 path {fill: var(--jp-warn-color0);} .bp3-button-text path { fill: var(--jp-inverse-layout-color3);} .jp-icon-brand0 path { fill: var(--jp-brand-color0);} text.terms { fill: #616161;} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "css_str = '<style> \\\n",
    ".jp-Button path { fill: #616161;} \\\n",
    "text.terms { fill: #616161;} \\\n",
    ".jp-icon-warn0 path {fill: var(--jp-warn-color0);} \\\n",
    ".bp3-button-text path { fill: var(--jp-inverse-layout-color3);} \\\n",
    ".jp-icon-brand0 path { fill: var(--jp-brand-color0);} \\\n",
    "text.terms { fill: #616161;} \\\n",
    "</style>'\n",
    "display(HTML(css_str ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c75e74fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "while 'juxtorpus' not in os.listdir():\n",
    "    os.chdir('../')\n",
    "# if  not 'juxtorpus' in os.listdir():\n",
    "#     os.chdir('../../../')\n",
    "assert 'juxtorpus' in os.listdir(), f\"Working directory should be at juxtorpus. But at {os.getcwd()}\"\n",
    "f\"Working directory: {os.getcwd()}\"\n",
    "\n",
    "# imports\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from juxtorpus.corpus import Corpus\n",
    "from juxtorpus.corpus.processors import process\n",
    "from juxtorpus.corpus.app import App\n",
    "from juxtorpus.corpus.topic_model import LDA\n",
    "from juxtorpus.viz.corpus import timeline, timelines, wordcloud, wordclouds\n",
    "from juxtorpus.viz.item_timeline import ItemTimeline\n",
    "from juxtorpus.matchers import is_hashtag\n",
    "\n",
    "from juxtorpus import Jux\n",
    "from juxtorpus.corpus.corpora import Corpora\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from atap_widgets.concordance import ConcordanceTable, ConcordanceWidget, ConcordanceLoader\n",
    "from atap_widgets.concordance import prepare_text_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996efaee",
   "metadata": {},
   "source": [
    "# Part 1. Corpus Building and Exploration\n",
    "\n",
    "#### The **Corpus** package is the essential platform for text operations and explorations. Users can upload or link their text collections with associated metadata, then compile the selected texts as a *Corpus* object. A *Corpus* object consists of a number of *documents* and the metadata that describe the documents, such as *title*, *publish date*, *author*, *word count* etc.\n",
    "#### A corpus can be built with either codes or an interactive widget within this notebook. When the input data are in the format of a spreadsheet, each row of data will be come one document. The user needs to specify the column for the text contents, and all other columns are compiled as associating metadata. The data type, e.g. *numeric*, *text*, *datetime*, *category*, need to be determined on the corpus building, and this affects how each meta data can be used in the further slicing operations.\n",
    "#### Once a corpus is built, the user is provided some basic out-of-box tools to explore the text contents or metadata, such as generating a word frequency table, plotting a word cloud, create a timeline plot of the documents or certain patterns in the text, or to perform certain analysis on the corpus with either ATAP or external tools, e.g. running *concordance tool*, *quotation tool* or *LDA topic modelling* etc.\n",
    "### The following section will demonstrate how to upload your text, build a corpus and explore it's contents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a563ef5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1 Upload your text and build a Corpus with corpus.widget()\n",
    "\n",
    "#### The **Corpora()** creates a corpus container that holds many Corpus objects. Each corpus can be built and named within the builder widget after the text contents are uploaded. Once the column of text is selected, and the data type of each meta data is set, the user can name the corpus and click on the button **Build**. If no name is manually given, a random name will be given to the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31cfc430-7e45-4269-a3b7-15ad4df50340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817d5d01a3b34de58e8440096e6016ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(description='Upload a Corpus', layout=Layout(width='300px'), style=ButtonStyle()), Labelâ€¦"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpora = Corpora()\n",
    "corpora.widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aa72d29-7d92-4be4-ba91-8199b83035e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'auspol'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cols = ['id', 'created_at', 'source', 'location', 'text', 'retweet_count', 'lang', 'possibly_sensitive', 'tweet_type']\n",
    "dtypes = ['Int64', 'category', 'string', 'Int64', 'category', 'category', 'category']\n",
    "\n",
    "df = pd.read_csv(Path('./notebooks/demos/Sample_Auspol_Tweets_Full.csv'), \n",
    "                 usecols=use_cols, \n",
    "                 dtype={'id': 'Int64', 'source': 'category', 'location':str, 'text':str, 'retweet_count':int, 'lang': 'category', 'tweet_type': 'category'})\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "#corpus = process(Corpus.from_dataframe(df, col_doc='text', name='auspol'), nlp=spacy.blank('en'))\n",
    "corpus = Corpus.from_dataframe(df, col_doc='text', name='auspol')\n",
    "\n",
    "corpus.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfa41c76-cd92-4c74-afbe-bf789c33f3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'customer-service'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use_cols = ['author_id', 'inbound', 'created_at', 'text', 'response_tweet_id', 'in_response_to_tweet_id', 'company', 'conversation']\n",
    "# dtypes = ['Int64', 'category', 'string', 'string', 'Int64', 'Int64', 'category', 'category']\n",
    "\n",
    "# df = pd.read_csv(Path('./notebooks/demos/taster_workshop/twcs_sel.csv'), \n",
    "#                  usecols=use_cols, \n",
    "#                  dtype={'author_id': 'Int64',\n",
    "#                         'inbound': 'category',\n",
    "#                         'created_at': str,\n",
    "#                         'text':str,\n",
    "#                         'response_tweet_id': 'Int64',\n",
    "#                         'response_tweet_id': 'Int64',\n",
    "#                         'company': 'category', \n",
    "#                         'conversation': 'category'})\n",
    "import pickle\n",
    "with open('./notebooks/demos/taster_workshop/twcs_sel.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "# df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "#corpus = process(Corpus.from_dataframe(df, col_doc='text', name='auspol'), nlp=spacy.blank('en'))\n",
    "corpus = Corpus.from_dataframe(df, col_doc='text', name='customer-service')\n",
    "\n",
    "corpus.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ee12e56-1a4d-4b43-b36a-7779cbef1f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817d5d01a3b34de58e8440096e6016ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(description='Hide', layout=Layout(width='300px'), style=ButtonStyle()), VBox(children=(Hâ€¦"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpora.add(corpus)\n",
    "corpora.widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43243054-97e1-4816-948e-5e4fce9e7fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = corpus.to_dataframe()\n",
    "df2.to_csv('./notebooks/demos/taster_workshop/twcs_sel2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61cff1c6-26bf-40f1-9fc9-806bddf91018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c96a4344b814e3f8a5376b9020c3c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(description='Show Builder', style=ButtonStyle()), Label(value='', layout=Layout(height='â€¦"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpora.add(corpus)\n",
    "corpora.widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d65e0a3-bda8-46f4-9742-a8ebb226d506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ddf04d9fbc149a799d1cf104637af94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', description='Keyword(s):'), HBox(children=(Checkbox(value=False, description='Enâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124.31303654203657\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "\n",
    "DataCSV = ConcordanceLoader(type='dataframe', df_input=df)\n",
    "DataCSV.show()\n",
    "\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90e62445-907f-41e4-9d75-2729cf46f1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63adf5e04e98474aad0d39db46672301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', description='Keyword(s):'), HBox(children=(Checkbox(value=False, description='Enâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0160403330228291\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "#corpus = Corpus.from_dataframe(df, col_doc='text', name='auspol-plain')\n",
    "start = timer()\n",
    "\n",
    "DataCSV = ConcordanceLoader(type='corpus', df_input=corpora['test2'])\n",
    "DataCSV.show()\n",
    "\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e5cbc6-3004-4830-a864-b17b01828f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765a5b07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Alternatively, a corpus can be built with the code and added to the corpora container.\n",
    "# corpora.add(corpus)   # alternatively\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781cfe4f-1fba-4a6d-9eee-5eaf0782dd01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2c2c84-8983-4bb1-a7b6-c2362e29ab8a",
   "metadata": {},
   "source": [
    "## Exploring the Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481024b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus = corpora['auspol']\n",
    "print('This table summarise the basic information of the corpus')\n",
    "corpus.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6876795-fcf0-4aac-afb6-bca1b19e2fab",
   "metadata": {},
   "source": [
    "### Corpus Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e1ba84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_WORDS = 100\n",
    "TYPE = 'word'\n",
    "# TYPE = 'hashtag'\n",
    "# TYPE = 'mention'\n",
    "print('Generate a word cloud with one line of code')\n",
    "corpus.viz.wordcloud(max_words=MAX_WORDS, word_type=TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb4bf6a-0366-4a76-809c-1be5c266deae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_WORDS = 100\n",
    "# TYPE = 'word'\n",
    "TYPE = 'hashtag'\n",
    "# TYPE = 'mention'\n",
    "print('Or make a wordcloud focusing on another predefined pattern - Hashtag')\n",
    "corpus.viz.wordcloud(max_words=MAX_WORDS, word_type=TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05676f0c-b493-4eaf-b267-fbfb0a68a097",
   "metadata": {},
   "source": [
    "### A Timeline of Daily Tweets Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53e89e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FREQ = '1w'\n",
    "# FREQ = '1m'\n",
    "FREQ = '1d'\n",
    "COL_TIME = 'created_at'\n",
    "corpus.viz.timeline(COL_TIME, freq=FREQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78337af1-80ff-4b8d-b219-64cdba0824b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Can also aggregate the data by different periods, e.g. weekly tweeting numbers')\n",
    "corpus.viz.timeline(COL_TIME, freq='1w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfff5001",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "COL_TIME = 'created_at'\n",
    "FREQ = '1w'\n",
    "\n",
    "# user defined function in creating a custom dtm (document-term-matrix)\n",
    "matcher = is_hashtag(corpus.nlp.vocab)\n",
    "def extract_hashtags(doc): return [doc[s:e].text.lower() for _, s, e in matcher(doc)]\n",
    "corpus.create_custom_dtm(extract_hashtags)\n",
    "\n",
    "print('Extract all Hashtags and display their weekly trends\\n - Click legend to deselect items\\n - Use the search box to display specific hashtag')\n",
    "item_timeline = ItemTimeline.from_corpus(corpus, COL_TIME, FREQ, custom_dtm=True)\n",
    "item_timeline.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab45c0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Corpus Slicer - creating a subcorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3724c2f3-e973-4871-b461-339964acfe59",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Slice the corpus by categorical metadata - Single or Multiple Choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e2e5aa-a3f3-4e4b-82f1-e205608d7b5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_corpus = corpora['auspol'].slicer.filter_by_item('lang', 'en')\n",
    "temp_corpus.name = 'auspol-en'\n",
    "corpora.add(temp_corpus)\n",
    "#\n",
    "temp_corpus = corpora['auspol-en'].slicer.filter_by_item('source', ['Twitter for iPad', 'Twitter for iPhone', 'Twitter for Mac'])\n",
    "temp_corpus.name = 'Apple'\n",
    "corpora.add(temp_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a356cb-94c0-4965-9b4c-b1cdb936e102",
   "metadata": {},
   "source": [
    "## Slice the corpus by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4092fd67-86aa-4bd3-9582-c16dceb470e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_corpus = corpora['auspol-en'].slicer.filter_by_datetime('created_at', start='01/03/2022', end='01/06/2022')\n",
    "temp_corpus.name = 'Autumn22'\n",
    "corpora.add(temp_corpus)\n",
    "#\n",
    "temp_corpus = corpora['auspol-en'].slicer.filter_by_datetime('created_at', start='01/09/2021', end='01/12/2021')\n",
    "temp_corpus.name = 'Spring21'\n",
    "corpora.add(temp_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d42b094-a033-4799-888e-4824748ce26f",
   "metadata": {},
   "source": [
    "## Slice the corpus by conditions, customised functions or slice the sub-corpora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012e707a-2e24-46e5-97f8-d6dbe89ffa26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "temp_corpus = corpora['auspol-en'].slicer.filter_by_condition('retweet_count', lambda cnt: cnt>3)\n",
    "temp_corpus.name = 'rt5+'\n",
    "corpora.add(temp_corpus)\n",
    "#\n",
    "L_func = '''lambda x: re.match(r'^.*android.*$', x, re.IGNORECASE) is not None'''\n",
    "temp_corpus = corpora['auspol-en'].slicer.filter_by_condition('source', eval(L_func))\n",
    "temp_corpus.name = 'Android'\n",
    "corpora.add(temp_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7b5d37-ad07-4431-ba78-a9ccf391ee20",
   "metadata": {},
   "source": [
    "## Interactive Widget for Slicing the Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abdff56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpora.widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f31bded-7c0a-49e8-9e80-d9d9d126b697",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Text Analysis on Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc432a90-733d-403f-aba9-fca2783c61ec",
   "metadata": {},
   "source": [
    "### All exploration can be easily repeated on sub-corpus, e.g. Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f69edc-bd46-4c25-8c86-e96519a5d69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora['Autumn22'].viz.wordcloud(max_words=MAX_WORDS, word_type='word')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dd6ee4-451c-4e40-ac35-58c87ea0bbdf",
   "metadata": {},
   "source": [
    "## LDA Topic Modelling + merge the outcome back to corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a094c100-242e-43ec-98be-978d6a976198",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPICS = 10\n",
    "lda = LDA(corpora['Autumn22'], num_topics=NUM_TOPICS).build('tf')\n",
    "lda.add_results_to_corpus()\n",
    "lda.widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e77ff02-2b07-4c12-aca3-e4054434b309",
   "metadata": {},
   "source": [
    "### Create sub-corpus based on the topic model associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35dec37-c162-40fd-a410-a0155772b060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sel_topics = {'a': 4,\n",
    "             'b': 10}\n",
    "for t, n in sel_topics.items():\n",
    "    temp_corpus = corpora['Autumn22'].slicer.filter_by_range('#lda_topic_{}'.format(n), min_=0.5)\n",
    "    temp_corpus.name = 'Autumn_T'+t\n",
    "    corpora.add(temp_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a8e72d-4bda-4e09-9d8e-352bdfdd7202",
   "metadata": {},
   "source": [
    "## Daily trends of the selected topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f39fa99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "COL_TIME = 'created_at'\n",
    "FREQ = '1d'\n",
    "timelines(corpora, ['Autumn_Ta', 'Autumn_Tb'], COL_TIME, FREQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8331c31c",
   "metadata": {},
   "source": [
    "# Jux - Compare and highlight the contrasts between any pair of corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afd4e26-79ab-4d92-a847-5b9792b3ce31",
   "metadata": {},
   "source": [
    "## Normal Corpus Wordcloud - Side by side, TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4040dd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS = 50\n",
    "# METRIC = 'tf'\n",
    "METRIC = 'tfidf'\n",
    "wordclouds(corpora, ['Autumn22', 'Spring21'], max_words=MAX_WORDS, metric=METRIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99db321-d21d-4e7e-9992-0a4d9294523b",
   "metadata": {},
   "source": [
    "## Jux Polarity Wordcloud - term frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029a1063",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC = 'tf'\n",
    "# METRIC = 'tfidf'\n",
    "# METRIC = 'log_likelihood'\n",
    "TOP = 80\n",
    "jux_season = Jux(corpora['Autumn22'], corpora['Spring21'])\n",
    "jux_season.polarity.wordcloud(METRIC, top=TOP, colours=('blue', 'red'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2933a392",
   "metadata": {},
   "source": [
    "### User defined tokenising function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a6ad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC = 'tf'\n",
    "\n",
    "# getting hashtags using a user defined function\n",
    "jux_season.polarity.wordcloud(METRIC, top=TOP, colours=('blue', 'red'), tokeniser_func=extract_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f906e7a7-1b59-47f2-a6f6-99663d9b7c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "colours = ('cyan', 'magenta')\n",
    "jux_platform = Jux(corpora['Apple'], corpora['Android'])\n",
    "jux_platform.polarity.wordcloud('tf', top=TOP, colours=colours)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fd3b07",
   "metadata": {},
   "source": [
    "# Keyword Analysis based on Log Likelihood\n",
    "\n",
    "Future plans: using Log likelihood to analyse keywords (currently being integrated)\n",
    "\n",
    "\n",
    "Rayson Paul., Berridge D. and Francis B. (2004). Extending the Cochran rule for the comparison of word frequencies between corpora. In Volume II of Purnelle G., Fairon C., Dister A. (eds.) Le poids des mots: Proceedings of the 7th International Conference on Statistical analysis of textual data (JADT 2004), Louvain-la-Neuve, Belgium, March 10-12, 2004, Presses universitaires de Louvain, pp. 926 - 936. ISBN 2-930344-50-4.\n",
    "https://ucrel.lancs.ac.uk/llwizard.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2201d743-93bf-47f4-a21a-21f863a65ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_corpus(row, colour):\n",
    "    return ['color:blue;']*len(row) if colour[row.name] else ['color:red;']*len(row)\n",
    "\n",
    "jun_ft = corpora['Spring21'].dtm.freq_table().series\n",
    "jan_ft = corpora['Autumn22'].dtm.freq_table().series\n",
    "df_ft = pd.concat([jun_ft.rename('Spring21'), jan_ft.rename('Autumn22')], axis=1, join='outer').fillna(0)\n",
    "colour = df_ft['Spring21'] > df_ft['Autumn22']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17632c21-88c4-4f51-be4b-926f35473160",
   "metadata": {},
   "outputs": [],
   "source": [
    "llv = Jux(corpora['Spring21'], corpora['Autumn22']) \\\n",
    "    .stats.log_likelihood_and_effect_size() \\\n",
    "    .sort_values(by='log_likelihood_llv', ascending=False)\n",
    "llv.iloc[:30].style \\\n",
    "    .apply(lambda row: style_corpus(row, colour), axis=1)\n",
    "\n",
    "# Red - Overused in January Corpus, Blue - Overused in July Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd59a7a",
   "metadata": {},
   "source": [
    "# Closing\n",
    "\n",
    "+ Release is planned tentatively in **May**.\n",
    "+ We will eventually integrate the ATAP tools together so you can easily access it under Corpus.\n",
    "+ Stay tuned at https://www.atap.edu.au/\n",
    "+ Feedback Survey at the end of the full workshop.\n",
    "+ Questions - I'll be around or email me at huen.chan@sydney.edu.au"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a135e486-3563-4f13-af55-516b517123bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
