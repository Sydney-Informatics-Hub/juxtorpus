{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3e60b09-c12a-421b-98bf-bf81104e16aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "\n",
    "dff = pd.read_csv('./twcs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a58ace9-f639-4aa7-a5ad-6e320fac0213",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['company'] = dff['author_id']\n",
    "dff['created_at'] = pd.to_datetime(dff['created_at'])\n",
    "dff.set_index('tweet_id', inplace=True)\n",
    "dff['in_response_to_tweet_id'] = dff['in_response_to_tweet_id'].astype('Int64')\n",
    "dff = dff.sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef20f435-7d4d-4a1a-8ac6-307d3b0e723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = dff.sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50aa76bb-fbfa-422d-9046-f693f28e504e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2811774, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05c69c32-f717-424d-8585-c75033ed30bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-10-31 22:10:47+00:00</td>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>sprintcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 22:11:45+00:00</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>115712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 22:08:27+00:00</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>115712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-10-31 21:54:49+00:00</td>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>sprintcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 21:49:35+00:00</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>115712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author_id  inbound                created_at  \\\n",
       "tweet_id                                                  \n",
       "1         sprintcare    False 2017-10-31 22:10:47+00:00   \n",
       "2             115712     True 2017-10-31 22:11:45+00:00   \n",
       "3             115712     True 2017-10-31 22:08:27+00:00   \n",
       "4         sprintcare    False 2017-10-31 21:54:49+00:00   \n",
       "5             115712     True 2017-10-31 21:49:35+00:00   \n",
       "\n",
       "                                                       text response_tweet_id  \\\n",
       "tweet_id                                                                        \n",
       "1         @115712 I understand. I would like to assist y...                 2   \n",
       "2             @sprintcare and how do you propose we do that               NaN   \n",
       "3         @sprintcare I have sent several private messag...                 1   \n",
       "4         @115712 Please send us a Private Message so th...                 3   \n",
       "5                                        @sprintcare I did.                 4   \n",
       "\n",
       "          in_response_to_tweet_id     company  \n",
       "tweet_id                                       \n",
       "1                               3  sprintcare  \n",
       "2                               1      115712  \n",
       "3                               4      115712  \n",
       "4                               5  sprintcare  \n",
       "5                               6      115712  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a242fc2-761e-4150-b6d8-84958a70d51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 518/518 [00:00<00:00, 2458.23it/s]\n"
     ]
    },
    {
     "ename": "IntCastingNaNError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIntCastingNaNError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conv, idx \u001b[38;5;129;01min\u001b[39;00m conv_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     21\u001b[0m     df\u001b[38;5;241m.\u001b[39mloc[idx, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconversation\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m conv\n\u001b[0;32m---> 22\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconversation\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconversation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mint\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m df\u001b[38;5;241m.\u001b[39mtail(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/atap/lib/python3.10/site-packages/pandas/core/generic.py:6240\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6233\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6234\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[:, i]\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m   6235\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[1;32m   6236\u001b[0m     ]\n\u001b[1;32m   6238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6239\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6240\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6243\u001b[0m \u001b[38;5;66;03m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/atap/lib/python3.10/site-packages/pandas/core/internals/managers.py:448\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mastype\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, dtype, copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m--> 448\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/atap/lib/python3.10/site-packages/pandas/core/internals/managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m):\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[0;32m~/miniconda3/envs/atap/lib/python3.10/site-packages/pandas/core/internals/blocks.py:526\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    524\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 526\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    528\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    529\u001b[0m newb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_block(new_values)\n",
      "File \u001b[0;32m~/miniconda3/envs/atap/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:299\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 299\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/atap/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:230\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    227\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/atap/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:140\u001b[0m, in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot astype a timedelta from [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] to [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(arr\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mfloating) \u001b[38;5;129;01mand\u001b[39;00m is_integer_dtype(dtype):\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_astype_float_to_int_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_object_dtype(arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m    143\u001b[0m \n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# if we have a datetime/timedelta array of objects\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# then coerce to a proper dtype and recall astype_nansafe\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_datetime64_dtype(dtype):\n",
      "File \u001b[0;32m~/miniconda3/envs/atap/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:182\u001b[0m, in \u001b[0;36m_astype_float_to_int_nansafe\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03mastype with a check preventing converting NaN to an meaningless integer value.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(values)\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IntCastingNaNError(\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert non-finite values (NA or inf) to integer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    184\u001b[0m     )\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;66;03m# GH#45151\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (values \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[0;31mIntCastingNaNError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "# Assign Conversation Numbers - Original non-parallelised code - Too slow 12 it/s\n",
    "df = dff.head(2000)\n",
    "def find_conv(resp_id, idx):\n",
    "    flag = True\n",
    "    while flag:\n",
    "        new_idx = resp_id[resp_id.isin(idx)].index\n",
    "        new_idx = set(new_idx).union(idx)\n",
    "        flag = len(new_idx) - len(idx)\n",
    "        idx = list(new_idx)\n",
    "    return idx \n",
    "\n",
    "conv_idx = df[pd.isna(df['in_response_to_tweet_id'])].index\n",
    "df.loc[conv_idx, 'conversation'] = conv_idx.values\n",
    "\n",
    "conv_dict = dict()\n",
    "for conv in tqdm(conv_idx):\n",
    "    idx = find_conv(df['in_response_to_tweet_id'], [conv])\n",
    "    conv_dict[conv] = idx\n",
    "\n",
    "for conv, idx in conv_dict.items():\n",
    "    df.loc[idx, 'conversation'] = conv\n",
    "df['conversation'] = df['conversation'].astype('int')\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e6bfa01-c1f8-48b6-a210-01bbbef312ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign conversation numbers - parallelised - Chunk of conversations - ok speed (chunk_size 10k~1.3k it/s, 50k~1.5k it/s, 500~ max speed 2.5k it/s)\n",
    "#df = dff\n",
    "\n",
    "def find_conv(resp_id, idx):\n",
    "    flag = True\n",
    "    while flag:\n",
    "        new_idx = resp_id[resp_id.isin(idx)].index\n",
    "        new_idx = set(new_idx).union(idx)\n",
    "        flag = len(new_idx) - len(idx)\n",
    "        idx = list(new_idx)\n",
    "    return idx\n",
    "\n",
    "# Function to process each conversation\n",
    "def process_conversation(conv, df):\n",
    "    idx = find_conv(df['in_response_to_tweet_id'], [conv])\n",
    "    return conv, idx\n",
    "\n",
    "def get_conversations(dff, chunk_size):\n",
    "    # # Parallelize the loop using concurrent.futures\n",
    "    # with concurrent.futures.ThreadPoolExecutor(max_workers=num_cores) as executor:\n",
    "    #     results = list(tqdm(executor.map(process_conversation, conv_idx), total=len(conv_idx)))\n",
    "\n",
    "    conv_idx = dff[pd.isna(dff['in_response_to_tweet_id'])].index\n",
    "    # Get the number of available CPU cores\n",
    "    num_cores = min(len(conv_idx), os.cpu_count())\n",
    "    # Print the number of cores used\n",
    "    print(\"Number of cores used:\", num_cores)\n",
    "\n",
    "    # Parallelize the loop using concurrent.futures\n",
    "    results = []\n",
    "    start_idx = 0\n",
    "    for i in range(len(conv_idx)//chunk_size):\n",
    "        end_idx = conv_idx[min(len(conv_idx), (i+1)*chunk_size)]\n",
    "        chunk_idx = conv_idx[i*chunk_size:min(len(conv_idx), (i+1)*chunk_size)]\n",
    "        if len(chunk_idx) == chunk_size:\n",
    "            df = dff.loc[dff.index.isin(list(range(start_idx,end_idx)))]\n",
    "        if len(chunk_idx) < chunk_size:\n",
    "            df = dff.loc[start_idx:]\n",
    "        \n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=num_cores) as executor:\n",
    "            temp = list(tqdm(executor.map(process_conversation, chunk_idx, [df]*len(chunk_idx)), total=len(chunk_idx)))\n",
    "        results += temp\n",
    "        start_idx = end_idx\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22f15d96-3e1a-4d6b-b5ff-89eb551bbc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cores used: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1268.99it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1252.09it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1278.39it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1355.36it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1288.95it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:08<00:00, 1159.53it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1264.97it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:08<00:00, 1243.05it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1255.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:08<00:00, 1243.70it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1347.60it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1423.80it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1388.69it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:06<00:00, 1478.93it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1377.49it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1386.83it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1380.07it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1302.55it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1335.91it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1317.08it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1284.46it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1341.51it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1369.68it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1298.87it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1343.16it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1334.69it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1377.46it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1322.27it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1317.66it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1292.00it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1321.38it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1271.95it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1306.50it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1334.18it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1337.39it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1389.06it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1354.93it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1407.27it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1356.37it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1351.78it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1405.02it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1402.97it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1302.16it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:06<00:00, 1449.40it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:05<00:00, 1842.94it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:05<00:00, 1685.59it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:06<00:00, 1509.05it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:05<00:00, 1827.52it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:05<00:00, 1729.68it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:06<00:00, 1458.12it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:05<00:00, 1875.97it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:05<00:00, 1838.89it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:05<00:00, 1853.77it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:05<00:00, 1709.66it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:06<00:00, 1439.02it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:06<00:00, 1502.44it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1422.75it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:06<00:00, 1454.24it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:06<00:00, 1576.99it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1393.07it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:06<00:00, 1463.53it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1386.93it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1401.60it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:06<00:00, 1436.11it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1344.03it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1427.34it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:06<00:00, 1457.44it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:06<00:00, 1468.64it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1391.25it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:06<00:00, 1546.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:06<00:00, 1438.44it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:06<00:00, 1435.76it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:06<00:00, 1448.69it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:06<00:00, 1577.58it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1413.66it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:06<00:00, 1454.82it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1402.65it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:06<00:00, 1560.99it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:06<00:00, 1580.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# Update the 'conversation' values in the DataFrame\n",
    "chunk_size = 10000\n",
    "results = get_conversations(dff, chunk_size)\n",
    "for conv, idx in results:\n",
    "    dff.loc[idx, 'conversation'] = conv\n",
    "\n",
    "dff['conversation'] = dff['conversation'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fbb679c1-4b1c-440a-9aec-72f89cc7f519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "      <th>company</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2987930</th>\n",
       "      <td>823862</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-11-29 19:24:29+00:00</td>\n",
       "      <td>@AskPayPal Könnt ihr mal bitte auf meine DM An...</td>\n",
       "      <td>2987929</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>823862</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987931</th>\n",
       "      <td>UPSHelp</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-11-30 07:56:27+00:00</td>\n",
       "      <td>@823863 Sorry to see this. If anything is dama...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2987932</td>\n",
       "      <td>UPSHelp</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987932</th>\n",
       "      <td>823863</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-11-30 01:41:28+00:00</td>\n",
       "      <td>@115817 seriously ?? https://t.co/i7JhZaQuGg</td>\n",
       "      <td>2987931</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>823863</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987933</th>\n",
       "      <td>UPSHelp</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-11-30 07:54:51+00:00</td>\n",
       "      <td>@823864 If you need assistance, please use the...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2987934</td>\n",
       "      <td>UPSHelp</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987934</th>\n",
       "      <td>823864</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-11-30 01:40:49+00:00</td>\n",
       "      <td>Second day (night) in a row my package is \"on ...</td>\n",
       "      <td>2987935,2987933</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>823864</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987936</th>\n",
       "      <td>UPSHelp</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-11-30 07:48:01+00:00</td>\n",
       "      <td>@823865 If you need assistance, please use the...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2987937</td>\n",
       "      <td>UPSHelp</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987937</th>\n",
       "      <td>823865</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-11-30 01:39:12+00:00</td>\n",
       "      <td>@115817 @UPSHelp Why does the tracking record ...</td>\n",
       "      <td>2987936</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>823865</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987938</th>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-11-22 07:49:52+00:00</td>\n",
       "      <td>@823866 当サイトからそのようなメールをお送りすることはございません。当サイトの名をか...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2987939</td>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987939</th>\n",
       "      <td>823866</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-11-22 07:41:45+00:00</td>\n",
       "      <td>いきなり来たんだけど\\nなんですかこれ！！？\\n\\n@120465 https://t.co...</td>\n",
       "      <td>2987938</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>823866</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987940</th>\n",
       "      <td>783956</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-11-22 07:15:45+00:00</td>\n",
       "      <td>@Safaricom_Care It's almost clocking 24hrs sin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2811285</td>\n",
       "      <td>783956</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987941</th>\n",
       "      <td>AirAsiaSupport</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-11-22 07:55:05+00:00</td>\n",
       "      <td>@823867 we have replied you via DM.Thanks-Emir</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2987942</td>\n",
       "      <td>AirAsiaSupport</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987942</th>\n",
       "      <td>823867</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-11-22 07:30:39+00:00</td>\n",
       "      <td>Hai @AirAsiaSupport #asking how many days need...</td>\n",
       "      <td>2987941</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>823867</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987943</th>\n",
       "      <td>AirAsiaSupport</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-11-22 07:54:57+00:00</td>\n",
       "      <td>@823868 Sorry but kindly try to clear browser,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2987944</td>\n",
       "      <td>AirAsiaSupport</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987944</th>\n",
       "      <td>823868</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-11-22 07:43:36+00:00</td>\n",
       "      <td>@AirAsiaSupport \\n\\nI am unable to do web chec...</td>\n",
       "      <td>2987943</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>823868</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987945</th>\n",
       "      <td>VirginTrains</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-11-22 08:27:34+00:00</td>\n",
       "      <td>@524544 That's a Peak service. The 09:56 is th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2987946</td>\n",
       "      <td>VirginTrains</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987946</th>\n",
       "      <td>524544</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-11-22 08:25:48+00:00</td>\n",
       "      <td>@VirginTrains Hope you are well? Does the 9.30...</td>\n",
       "      <td>2987945</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>524544</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987947</th>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-11-22 08:43:51+00:00</td>\n",
       "      <td>@823869 Hey, we'd be happy to look into this f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2987948</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987948</th>\n",
       "      <td>823869</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-11-22 08:35:16+00:00</td>\n",
       "      <td>@115714 wtf!? I’ve been having really shitty s...</td>\n",
       "      <td>2987947</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>823869</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987949</th>\n",
       "      <td>AldiUK</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-11-22 08:31:24+00:00</td>\n",
       "      <td>@823870 Sounds delicious, Sarah! 😋 https://t.c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2987950</td>\n",
       "      <td>AldiUK</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987950</th>\n",
       "      <td>823870</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-11-21 22:01:04+00:00</td>\n",
       "      <td>@AldiUK  warm sloe gin mince pies with ice cre...</td>\n",
       "      <td>2987951,2987949</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>823870</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author_id  inbound                created_at  \\\n",
       "tweet_id                                                      \n",
       "2987930           823862     True 2017-11-29 19:24:29+00:00   \n",
       "2987931          UPSHelp    False 2017-11-30 07:56:27+00:00   \n",
       "2987932           823863     True 2017-11-30 01:41:28+00:00   \n",
       "2987933          UPSHelp    False 2017-11-30 07:54:51+00:00   \n",
       "2987934           823864     True 2017-11-30 01:40:49+00:00   \n",
       "2987936          UPSHelp    False 2017-11-30 07:48:01+00:00   \n",
       "2987937           823865     True 2017-11-30 01:39:12+00:00   \n",
       "2987938       AmazonHelp    False 2017-11-22 07:49:52+00:00   \n",
       "2987939           823866     True 2017-11-22 07:41:45+00:00   \n",
       "2987940           783956     True 2017-11-22 07:15:45+00:00   \n",
       "2987941   AirAsiaSupport    False 2017-11-22 07:55:05+00:00   \n",
       "2987942           823867     True 2017-11-22 07:30:39+00:00   \n",
       "2987943   AirAsiaSupport    False 2017-11-22 07:54:57+00:00   \n",
       "2987944           823868     True 2017-11-22 07:43:36+00:00   \n",
       "2987945     VirginTrains    False 2017-11-22 08:27:34+00:00   \n",
       "2987946           524544     True 2017-11-22 08:25:48+00:00   \n",
       "2987947       sprintcare    False 2017-11-22 08:43:51+00:00   \n",
       "2987948           823869     True 2017-11-22 08:35:16+00:00   \n",
       "2987949           AldiUK    False 2017-11-22 08:31:24+00:00   \n",
       "2987950           823870     True 2017-11-21 22:01:04+00:00   \n",
       "\n",
       "                                                       text response_tweet_id  \\\n",
       "tweet_id                                                                        \n",
       "2987930   @AskPayPal Könnt ihr mal bitte auf meine DM An...           2987929   \n",
       "2987931   @823863 Sorry to see this. If anything is dama...               NaN   \n",
       "2987932        @115817 seriously ?? https://t.co/i7JhZaQuGg           2987931   \n",
       "2987933   @823864 If you need assistance, please use the...               NaN   \n",
       "2987934   Second day (night) in a row my package is \"on ...   2987935,2987933   \n",
       "2987936   @823865 If you need assistance, please use the...               NaN   \n",
       "2987937   @115817 @UPSHelp Why does the tracking record ...           2987936   \n",
       "2987938   @823866 当サイトからそのようなメールをお送りすることはございません。当サイトの名をか...               NaN   \n",
       "2987939   いきなり来たんだけど\\nなんですかこれ！！？\\n\\n@120465 https://t.co...           2987938   \n",
       "2987940   @Safaricom_Care It's almost clocking 24hrs sin...               NaN   \n",
       "2987941      @823867 we have replied you via DM.Thanks-Emir               NaN   \n",
       "2987942   Hai @AirAsiaSupport #asking how many days need...           2987941   \n",
       "2987943   @823868 Sorry but kindly try to clear browser,...               NaN   \n",
       "2987944   @AirAsiaSupport \\n\\nI am unable to do web chec...           2987943   \n",
       "2987945   @524544 That's a Peak service. The 09:56 is th...               NaN   \n",
       "2987946   @VirginTrains Hope you are well? Does the 9.30...           2987945   \n",
       "2987947   @823869 Hey, we'd be happy to look into this f...               NaN   \n",
       "2987948   @115714 wtf!? I’ve been having really shitty s...           2987947   \n",
       "2987949   @823870 Sounds delicious, Sarah! 😋 https://t.c...               NaN   \n",
       "2987950   @AldiUK  warm sloe gin mince pies with ice cre...   2987951,2987949   \n",
       "\n",
       "          in_response_to_tweet_id         company  conversation  \n",
       "tweet_id                                                         \n",
       "2987930                      <NA>          823862          <NA>  \n",
       "2987931                   2987932         UPSHelp          <NA>  \n",
       "2987932                      <NA>          823863          <NA>  \n",
       "2987933                   2987934         UPSHelp          <NA>  \n",
       "2987934                      <NA>          823864          <NA>  \n",
       "2987936                   2987937         UPSHelp          <NA>  \n",
       "2987937                      <NA>          823865          <NA>  \n",
       "2987938                   2987939      AmazonHelp          <NA>  \n",
       "2987939                      <NA>          823866          <NA>  \n",
       "2987940                   2811285          783956          <NA>  \n",
       "2987941                   2987942  AirAsiaSupport          <NA>  \n",
       "2987942                      <NA>          823867          <NA>  \n",
       "2987943                   2987944  AirAsiaSupport          <NA>  \n",
       "2987944                      <NA>          823868          <NA>  \n",
       "2987945                   2987946    VirginTrains          <NA>  \n",
       "2987946                      <NA>          524544          <NA>  \n",
       "2987947                   2987948      sprintcare          <NA>  \n",
       "2987948                      <NA>          823869          <NA>  \n",
       "2987949                   2987950          AldiUK          <NA>  \n",
       "2987950                      <NA>          823870          <NA>  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "606efda8-5dfb-4bcb-8aa3-c45708548fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cores used: 10\n"
     ]
    }
   ],
   "source": [
    "missed = dff[dff['conversation'].isna()]\n",
    "missed_resp_id = missed['in_response_to_tweet_id'].values\n",
    "idx = list(set(missed_resp_id).intersection(dff.index))\n",
    "missed_resp = dff.loc[idx]\n",
    "newdf = pd.concat([missed, missed_resp]).sort_index(ascending=True).drop_duplicates()\n",
    "\n",
    "missed_conv_idx = newdf[pd.isna(newdf['in_response_to_tweet_id'])].index\n",
    "results_missed = []\n",
    "for conv in tqdm(missed_conv_idx):\n",
    "    idx = find_conv(newdf['in_response_to_tweet_id'], [conv])\n",
    "    results_missed.append((conv, idx))\n",
    "\n",
    "for conv, idx in results_missed:\n",
    "    dff.loc[idx, 'conversation'] = conv\n",
    "\n",
    "dff['conversation'] = dff['conversation'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9e2511eb-e901-40b3-84d6-d0e5dc61e6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4413/4413 [00:14<00:00, 300.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# There are missed data in the dataframe for some reason. Find all and assign conversation numbers again.\n",
    "conv_idx = newdf[pd.isna(newdf['in_response_to_tweet_id'])].index\n",
    "results2 = []\n",
    "for conv in tqdm(conv_idx):\n",
    "    idx = find_conv(newdf['in_response_to_tweet_id'], [conv])\n",
    "    results2.append((conv, idx))\n",
    "\n",
    "dff.to_csv('twcs_proccessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7250fe0d-f356-46d2-bc1a-249137cb98fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 794335/794335 [00:28<00:00, 27468.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# Assign Company to conversations\n",
    "\n",
    "def process_group(group_tuple):\n",
    "    group_name, group_data = group_tuple\n",
    "    grp_idx = group_data.index\n",
    "    companies = [n.lower() for n in group_data['author_id'].unique() if not n.isnumeric()]\n",
    "    # It is possible that multiple companies got involved into the same conversation, often both merchant and logistic company.\n",
    "    return ', '.join(sorted(companies)), grp_idx\n",
    "    # if len(authors) == 1:\n",
    "    #     company = authors[0]\n",
    "    #     return company, grp_idx\n",
    "    # else:\n",
    "    #     print('Conversation {} has more than one company: {}'.format(group_name, authors))\n",
    "    #     return None\n",
    "\n",
    "# Your existing code...\n",
    "idxGroup = dict()\n",
    "grouped = dff.groupby('conversation')\n",
    "\n",
    "\n",
    "for group in tqdm(grouped):\n",
    "    company, grp_idx = process_group(group)\n",
    "    if company in idxGroup:\n",
    "        idxGroup[company].extend(grp_idx)\n",
    "    else:\n",
    "        idxGroup[company] = list(grp_idx)    \n",
    "\n",
    "\n",
    "# Assign the 'company' values to the DataFrame\n",
    "for company, idx in idxGroup.items():\n",
    "    dff.loc[list(set(idx)), 'company'] = company\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "acfb3726-95e0-4d21-9e9f-6f8b931e087d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "      <th>company</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2979680</th>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-11-30 04:08:00+00:00</td>\n",
       "      <td>@249801 Please reach out to us by phone or cha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2979681</td>\n",
       "      <td>amazonhelp, upshelp</td>\n",
       "      <td>2979681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979681</th>\n",
       "      <td>249801</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-11-30 03:58:22+00:00</td>\n",
       "      <td>Hey @115817, thanks for not delivering my pack...</td>\n",
       "      <td>2979680,2979682</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>amazonhelp, upshelp</td>\n",
       "      <td>2979681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979682</th>\n",
       "      <td>UPSHelp</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-11-30 04:25:28+00:00</td>\n",
       "      <td>@249801 I am sorry to hear that your package w...</td>\n",
       "      <td>2980530</td>\n",
       "      <td>2979681</td>\n",
       "      <td>amazonhelp, upshelp</td>\n",
       "      <td>2979681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980530</th>\n",
       "      <td>221581</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-11-30 04:45:53+00:00</td>\n",
       "      <td>@UPSHelp @249801 Dont feel too bad. I have a N...</td>\n",
       "      <td>2980531</td>\n",
       "      <td>2979682</td>\n",
       "      <td>amazonhelp, upshelp</td>\n",
       "      <td>2979681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980531</th>\n",
       "      <td>249801</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-11-30 04:49:13+00:00</td>\n",
       "      <td>@221581 @UPSHelp wow that sucks. Hope you get ...</td>\n",
       "      <td>2980532</td>\n",
       "      <td>2980530</td>\n",
       "      <td>amazonhelp, upshelp</td>\n",
       "      <td>2979681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980532</th>\n",
       "      <td>221581</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-11-30 04:51:37+00:00</td>\n",
       "      <td>@249801 @UPSHelp I am lucky that Amazon does t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2980531</td>\n",
       "      <td>amazonhelp, upshelp</td>\n",
       "      <td>2979681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author_id  inbound                created_at  \\\n",
       "tweet_id                                                  \n",
       "2979680   AmazonHelp    False 2017-11-30 04:08:00+00:00   \n",
       "2979681       249801     True 2017-11-30 03:58:22+00:00   \n",
       "2979682      UPSHelp    False 2017-11-30 04:25:28+00:00   \n",
       "2980530       221581     True 2017-11-30 04:45:53+00:00   \n",
       "2980531       249801     True 2017-11-30 04:49:13+00:00   \n",
       "2980532       221581     True 2017-11-30 04:51:37+00:00   \n",
       "\n",
       "                                                       text response_tweet_id  \\\n",
       "tweet_id                                                                        \n",
       "2979680   @249801 Please reach out to us by phone or cha...               NaN   \n",
       "2979681   Hey @115817, thanks for not delivering my pack...   2979680,2979682   \n",
       "2979682   @249801 I am sorry to hear that your package w...           2980530   \n",
       "2980530   @UPSHelp @249801 Dont feel too bad. I have a N...           2980531   \n",
       "2980531   @221581 @UPSHelp wow that sucks. Hope you get ...           2980532   \n",
       "2980532   @249801 @UPSHelp I am lucky that Amazon does t...               NaN   \n",
       "\n",
       "          in_response_to_tweet_id              company  conversation  \n",
       "tweet_id                                                              \n",
       "2979680                   2979681  amazonhelp, upshelp       2979681  \n",
       "2979681                      <NA>  amazonhelp, upshelp       2979681  \n",
       "2979682                   2979681  amazonhelp, upshelp       2979681  \n",
       "2980530                   2979682  amazonhelp, upshelp       2979681  \n",
       "2980531                   2980530  amazonhelp, upshelp       2979681  \n",
       "2980532                   2980531  amazonhelp, upshelp       2979681  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.loc[dff['conversation']==2979681]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8f4f619e-f375-4b85-83bf-2a9b7f82402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.to_csv('twcs_proccessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be51aab9-ddd7-4d49-82be-2833d99fbd69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff['company'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff33cd7a-4026-46f8-80c5-a7df3e2f92c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c02245-1d73-4a11-9a90-c247b22e1de4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "713bfd67-d815-4c06-b4c6-38dbf925118f",
   "metadata": {},
   "source": [
    "## No use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a9882e-062f-4596-9457-2a5acd70b5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign conversation numbers - parallelised - very slow ~100it/s\n",
    "df = dff\n",
    "\n",
    "def find_conv(resp_id, idx):\n",
    "    flag = True\n",
    "    while flag:\n",
    "        new_idx = resp_id[resp_id.isin(idx)].index\n",
    "        new_idx = set(new_idx).union(idx)\n",
    "        flag = len(new_idx) - len(idx)\n",
    "        idx = list(new_idx)\n",
    "    return idx\n",
    "\n",
    "conv_idx = df[pd.isna(df['in_response_to_tweet_id'])].index\n",
    "df.loc[conv_idx, 'conversation'] = conv_idx.values\n",
    "\n",
    "# Function to process each conversation\n",
    "def process_conversation(conv):\n",
    "    idx = find_conv(df['in_response_to_tweet_id'], [conv])\n",
    "    return conv, idx\n",
    "\n",
    "# Get the number of available CPU cores\n",
    "num_cores = min(len(conv_idx), os.cpu_count())\n",
    "# Print the number of cores used\n",
    "print(\"Number of cores used:\", num_cores)\n",
    "\n",
    "# Parallelize the loop using concurrent.futures\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=num_cores) as executor:\n",
    "    results = list(tqdm(executor.map(process_conversation, conv_idx), total=len(conv_idx)))\n",
    "\n",
    "# Update the 'conversation' values in the DataFrame\n",
    "for conv, idx in results:\n",
    "    df.loc[idx, 'conversation'] = conv\n",
    "\n",
    "df['conversation'] = df['conversation'].astype('Int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3912909-6531-4e84-8de4-41efc99efacb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
